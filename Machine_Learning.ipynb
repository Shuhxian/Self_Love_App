{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6GiixMG6QoiyjGloYh2+v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandontan99/Self_Love_App/blob/master/Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnXKhzrzjYOx"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z0aAfTihkgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b9eca93-9bff-4aa4-e46f-18a62d9a4c07"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/brandontan99/Self_Love_App.git\n",
        "%cd /content/Self_Love_App\n",
        "!pip install scikit-multilearn\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.feature_selection import chi2, SelectKBest\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from skmultilearn.adapt import *\n",
        "from skmultilearn.problem_transform import *\n",
        "from skmultilearn.ensemble import * \n",
        "from skmultilearn.cluster import *\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from data_cleaning import data_cleaning\n",
        "from Data_Normalization import data_encoding, data_normalization\n",
        "from feature_selection import *\n",
        "\n",
        "# random seed\n",
        "seed = 1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'Self_Love_App'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (150/150), done.\u001b[K\n",
            "remote: Total 175 (delta 96), reused 50 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (175/175), 1.84 MiB | 13.36 MiB/s, done.\n",
            "Resolving deltas: 100% (96/96), done.\n",
            "/content/Self_Love_App\n",
            "Collecting scikit-multilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.1MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsmsNdXyyCm5"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "2P6H4tWRDWaO",
        "outputId": "05a74e6c-9138-4797-ae57-e4a92843c969"
      },
      "source": [
        "df = pd.read_csv(\"WID3006 ML Questionnaire.csv\")\n",
        "df_cleaned = data_cleaning(df)\n",
        "df_encoded = data_encoding(df_cleaned)\n",
        "df_norm = data_normalization(df_encoded)\n",
        "df_norm"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender: _Male</th>\n",
              "      <th>What is your current occupation?_Retired</th>\n",
              "      <th>What is your current occupation?_Unemployed</th>\n",
              "      <th>What is your current occupation?_University student</th>\n",
              "      <th>What boosts your confidence ? _By leading others to success</th>\n",
              "      <th>What boosts your confidence ? _Get the most/ special attention among the members</th>\n",
              "      <th>What boosts your confidence ? _When someone acknowledges you</th>\n",
              "      <th>What boosts your confidence ? _When you accomplish a project</th>\n",
              "      <th>I prefer to spend my money on...._Food</th>\n",
              "      <th>I prefer to spend my money on...._Home Improvements</th>\n",
              "      <th>I prefer to spend my money on...._The latest fashion</th>\n",
              "      <th>I prefer to spend my money on...._The latest technology</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I make a chart or graph</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I talk to myself out loud</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I write it down in my calendar</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._Jotting it down on a scrap of paper</th>\n",
              "      <th>Choose a pet which you prefer to keep._Cat</th>\n",
              "      <th>Choose a pet which you prefer to keep._Dog</th>\n",
              "      <th>Choose a pet which you prefer to keep._Fish</th>\n",
              "      <th>Choose a pet which you prefer to keep._Hamster</th>\n",
              "      <th>Choose a pet which you prefer to keep._Horse</th>\n",
              "      <th>Choose a pet which you prefer to keep._I'm not a pet person</th>\n",
              "      <th>Choose a pet which you prefer to keep._Rabbit</th>\n",
              "      <th>Choose a pet which you prefer to keep._Snake</th>\n",
              "      <th>Choose a pet which you prefer to keep._Tortoise</th>\n",
              "      <th>What is your favorite time of the day?_Evening</th>\n",
              "      <th>What is your favorite time of the day?_Morning</th>\n",
              "      <th>What is your favorite time of the day?_Night</th>\n",
              "      <th>Would you rather visit the future or the past?_The future</th>\n",
              "      <th>Would you rather visit the future or the past?_The past</th>\n",
              "      <th>What do you worry more about the most?_Money</th>\n",
              "      <th>What do you worry more about the most?_The state of the world</th>\n",
              "      <th>What do you worry more about the most?_Your family and friends</th>\n",
              "      <th>What do you worry more about the most?_Your future</th>\n",
              "      <th>When you retire, you'd like to live..._Exactly where I live now</th>\n",
              "      <th>When you retire, you'd like to live..._In a hectic big city</th>\n",
              "      <th>When you retire, you'd like to live..._In a small town</th>\n",
              "      <th>When you retire, you'd like to live..._Overseas</th>\n",
              "      <th>When you retire, you'd like to live..._Traveling the world</th>\n",
              "      <th>What is your favorite color?_Blue</th>\n",
              "      <th>What is your favorite color?_Green</th>\n",
              "      <th>What is your favorite color?_Purple</th>\n",
              "      <th>What is your favorite color?_Red</th>\n",
              "      <th>What is your favorite color?_White</th>\n",
              "      <th>What is your favorite color?_Yellow</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By attending online courses</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By doing assignments</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By doing tutorial/lab questions</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By reading a physical book</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By reading an e-Book</th>\n",
              "      <th>Do you enjoy socializing with large groups of people?</th>\n",
              "      <th>Do you enjoy challenges?</th>\n",
              "      <th>How creative of a person do you think you are?</th>\n",
              "      <th>How logical of a person do you think you are?</th>\n",
              "      <th>Would you prefer to engage your brain more than your body?</th>\n",
              "      <th>Are you a curious person?</th>\n",
              "      <th>Are you a perfectionist?</th>\n",
              "      <th>Are you a trusting person?</th>\n",
              "      <th>Do you have lot of patience?</th>\n",
              "      <th>Do you organize your schedule well?</th>\n",
              "      <th>Do you like to sit in front of a computer for long hours?</th>\n",
              "      <th>Do you enjoy making others happy?</th>\n",
              "      <th>Can you understand others' perspectives and feelings?</th>\n",
              "      <th>How confident are you in your own abilities?</th>\n",
              "      <th>Sports and Outdoors</th>\n",
              "      <th>Games</th>\n",
              "      <th>Spiritual and Mental</th>\n",
              "      <th>Performing Arts</th>\n",
              "      <th>Arts and Craft</th>\n",
              "      <th>Food and Drinks</th>\n",
              "      <th>Collecting</th>\n",
              "      <th>Rejuvenation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192 rows × 72 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Gender: _Male  ...  Rejuvenation\n",
              "0                1  ...           0.0\n",
              "1                1  ...           0.0\n",
              "2                1  ...           0.0\n",
              "3                1  ...           0.0\n",
              "4                0  ...           0.0\n",
              "..             ...  ...           ...\n",
              "187              1  ...           0.0\n",
              "188              1  ...           0.0\n",
              "189              1  ...           0.0\n",
              "190              1  ...           0.0\n",
              "191              1  ...           0.0\n",
              "\n",
              "[192 rows x 72 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2MIs9nn6aoU",
        "outputId": "876bef29-6547-44a3-e8a3-6a7b199ff51c"
      },
      "source": [
        "for i, name in enumerate(df_norm.columns):\n",
        "  print(i, name)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Gender: _Male\n",
            "1 What is your current occupation?_Retired\n",
            "2 What is your current occupation?_Unemployed\n",
            "3 What is your current occupation?_University student\n",
            "4 What boosts your confidence ? _By leading others to success\n",
            "5 What boosts your confidence ? _Get the most/ special attention among the members\n",
            "6 What boosts your confidence ? _When someone acknowledges you\n",
            "7 What boosts your confidence ? _When you accomplish a project\n",
            "8 I prefer to spend my money on...._Food\n",
            "9 I prefer to spend my money on...._Home Improvements\n",
            "10 I prefer to spend my money on...._The latest fashion\n",
            "11 I prefer to spend my money on...._The latest technology\n",
            "12 How do you organize your thoughts? Please pick whichever is closest._I make a chart or graph\n",
            "13 How do you organize your thoughts? Please pick whichever is closest._I talk to myself out loud\n",
            "14 How do you organize your thoughts? Please pick whichever is closest._I write it down in my calendar\n",
            "15 How do you organize your thoughts? Please pick whichever is closest._Jotting it down on a scrap of paper\n",
            "16 Choose a pet which you prefer to keep._Cat\n",
            "17 Choose a pet which you prefer to keep._Dog\n",
            "18 Choose a pet which you prefer to keep._Fish\n",
            "19 Choose a pet which you prefer to keep._Hamster\n",
            "20 Choose a pet which you prefer to keep._Horse\n",
            "21 Choose a pet which you prefer to keep._I'm not a pet person\n",
            "22 Choose a pet which you prefer to keep._Rabbit\n",
            "23 Choose a pet which you prefer to keep._Snake\n",
            "24 Choose a pet which you prefer to keep._Tortoise\n",
            "25 What is your favorite time of the day?_Evening\n",
            "26 What is your favorite time of the day?_Morning\n",
            "27 What is your favorite time of the day?_Night\n",
            "28 Would you rather visit the future or the past?_The future\n",
            "29 Would you rather visit the future or the past?_The past\n",
            "30 What do you worry more about the most?_Money\n",
            "31 What do you worry more about the most?_The state of the world\n",
            "32 What do you worry more about the most?_Your family and friends\n",
            "33 What do you worry more about the most?_Your future\n",
            "34 When you retire, you'd like to live..._Exactly where I live now\n",
            "35 When you retire, you'd like to live..._In a hectic big city\n",
            "36 When you retire, you'd like to live..._In a small town\n",
            "37 When you retire, you'd like to live..._Overseas\n",
            "38 When you retire, you'd like to live..._Traveling the world\n",
            "39 What is your favorite color?_Blue\n",
            "40 What is your favorite color?_Green\n",
            "41 What is your favorite color?_Purple\n",
            "42 What is your favorite color?_Red\n",
            "43 What is your favorite color?_White\n",
            "44 What is your favorite color?_Yellow\n",
            "45 What is your learning style? (Pick one that benefit you the most)_By attending online courses\n",
            "46 What is your learning style? (Pick one that benefit you the most)_By doing assignments\n",
            "47 What is your learning style? (Pick one that benefit you the most)_By doing tutorial/lab questions\n",
            "48 What is your learning style? (Pick one that benefit you the most)_By reading a physical book\n",
            "49 What is your learning style? (Pick one that benefit you the most)_By reading an e-Book\n",
            "50 Do you enjoy socializing with large groups of people?\n",
            "51 Do you enjoy challenges?\n",
            "52 How creative of a person do you think you are?\n",
            "53 How logical of a person do you think you are?\n",
            "54 Would you prefer to engage your brain more than your body?\n",
            "55 Are you a curious person?\n",
            "56 Are you a perfectionist?\n",
            "57 Are you a trusting person?\n",
            "58 Do you have lot of patience?\n",
            "59 Do you organize your schedule well?\n",
            "60 Do you like to sit in front of a computer for long hours?\n",
            "61 Do you enjoy making others happy?\n",
            "62 Can you understand others' perspectives and feelings?\n",
            "63 How confident are you in your own abilities?\n",
            "64 Sports and Outdoors\n",
            "65 Games\n",
            "66 Spiritual and Mental\n",
            "67 Performing Arts\n",
            "68 Arts and Craft\n",
            "69 Food and Drinks\n",
            "70 Collecting\n",
            "71 Rejuvenation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "V9fBSm0zrTnq",
        "outputId": "ab56593b-6359-4418-b718-e133fb9f9c6e"
      },
      "source": [
        "x = filter_features(best_k_features, df_norm)\n",
        "x"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender: _Male</th>\n",
              "      <th>What is your current occupation?_Retired</th>\n",
              "      <th>What is your current occupation?_Unemployed</th>\n",
              "      <th>What is your current occupation?_University student</th>\n",
              "      <th>What boosts your confidence ? _By leading others to success</th>\n",
              "      <th>What boosts your confidence ? _Get the most/ special attention among the members</th>\n",
              "      <th>What boosts your confidence ? _When someone acknowledges you</th>\n",
              "      <th>What boosts your confidence ? _When you accomplish a project</th>\n",
              "      <th>I prefer to spend my money on...._Food</th>\n",
              "      <th>I prefer to spend my money on...._Home Improvements</th>\n",
              "      <th>I prefer to spend my money on...._The latest fashion</th>\n",
              "      <th>I prefer to spend my money on...._The latest technology</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I make a chart or graph</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I talk to myself out loud</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I write it down in my calendar</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._Jotting it down on a scrap of paper</th>\n",
              "      <th>Choose a pet which you prefer to keep._Cat</th>\n",
              "      <th>Choose a pet which you prefer to keep._Dog</th>\n",
              "      <th>Choose a pet which you prefer to keep._Fish</th>\n",
              "      <th>Choose a pet which you prefer to keep._Hamster</th>\n",
              "      <th>Choose a pet which you prefer to keep._Horse</th>\n",
              "      <th>Choose a pet which you prefer to keep._I'm not a pet person</th>\n",
              "      <th>Choose a pet which you prefer to keep._Rabbit</th>\n",
              "      <th>Choose a pet which you prefer to keep._Snake</th>\n",
              "      <th>Choose a pet which you prefer to keep._Tortoise</th>\n",
              "      <th>What is your favorite time of the day?_Evening</th>\n",
              "      <th>What is your favorite time of the day?_Morning</th>\n",
              "      <th>What is your favorite time of the day?_Night</th>\n",
              "      <th>Would you rather visit the future or the past?_The future</th>\n",
              "      <th>Would you rather visit the future or the past?_The past</th>\n",
              "      <th>What do you worry more about the most?_Money</th>\n",
              "      <th>What do you worry more about the most?_The state of the world</th>\n",
              "      <th>What do you worry more about the most?_Your family and friends</th>\n",
              "      <th>What do you worry more about the most?_Your future</th>\n",
              "      <th>When you retire, you'd like to live..._Exactly where I live now</th>\n",
              "      <th>When you retire, you'd like to live..._In a hectic big city</th>\n",
              "      <th>When you retire, you'd like to live..._In a small town</th>\n",
              "      <th>When you retire, you'd like to live..._Overseas</th>\n",
              "      <th>When you retire, you'd like to live..._Traveling the world</th>\n",
              "      <th>What is your favorite color?_Blue</th>\n",
              "      <th>What is your favorite color?_Green</th>\n",
              "      <th>What is your favorite color?_Purple</th>\n",
              "      <th>What is your favorite color?_Red</th>\n",
              "      <th>What is your favorite color?_White</th>\n",
              "      <th>What is your favorite color?_Yellow</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By attending online courses</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By doing assignments</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By doing tutorial/lab questions</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By reading a physical book</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By reading an e-Book</th>\n",
              "      <th>Do you enjoy socializing with large groups of people?</th>\n",
              "      <th>Do you enjoy challenges?</th>\n",
              "      <th>How creative of a person do you think you are?</th>\n",
              "      <th>How logical of a person do you think you are?</th>\n",
              "      <th>Would you prefer to engage your brain more than your body?</th>\n",
              "      <th>Are you a perfectionist?</th>\n",
              "      <th>Do you have lot of patience?</th>\n",
              "      <th>Do you organize your schedule well?</th>\n",
              "      <th>Do you like to sit in front of a computer for long hours?</th>\n",
              "      <th>Do you enjoy making others happy?</th>\n",
              "      <th>How confident are you in your own abilities?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Gender: _Male  ...  How confident are you in your own abilities?\n",
              "0                1  ...                                          0.50\n",
              "1                1  ...                                          1.00\n",
              "2                1  ...                                          0.75\n",
              "3                1  ...                                          0.75\n",
              "4                0  ...                                          1.00\n",
              "..             ...  ...                                           ...\n",
              "187              1  ...                                          0.75\n",
              "188              1  ...                                          0.75\n",
              "189              1  ...                                          0.50\n",
              "190              1  ...                                          0.75\n",
              "191              1  ...                                          0.25\n",
              "\n",
              "[192 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f0n58suGAiy"
      },
      "source": [
        "x = df_norm.iloc[:, :64]\n",
        "y = df_norm.iloc[:, 64:]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ece3V25n1Gar",
        "outputId": "c813cae6-d0eb-44c5-a16b-ba63064264d6"
      },
      "source": [
        "x_numpy, y_numpy = x.to_numpy(), y.to_numpy()\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=0.25, random_state=seed)\n",
        "print(\"Number of train dataset:\", len(x_train))\n",
        "print(\"Number of test dataset:\", len(x_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train dataset: 144\n",
            "Number of test dataset: 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "CEv85eH5JjE7",
        "outputId": "08250147-036d-4a2e-af1f-3fcb0cacbd31"
      },
      "source": [
        "# draw the distribution of the hobbies with a horizontal bar chart\n",
        "distribution_of_hobbies = y.sum().sort_values(ascending=False)\n",
        "distribution_of_hobbies_train_test = pd.DataFrame(np.concatenate([y_train.sum(axis=0)[:,None], y_test.sum(axis=0)[:,None]], axis=1), index=y.columns, columns=[\"Train\",\"Test\"])\n",
        "distribution_of_hobbies_train_test = distribution_of_hobbies_train_test.reindex(distribution_of_hobbies.index)\n",
        "distribution_of_hobbies_train_test.plot(kind='barh', figsize=(6, 6), title=\"Frequency of each Hobbes chosen\", stacked=True)\n",
        "\n",
        "# put the frequency text on the right of the bar chart\n",
        "for i, (row_index, row) in enumerate(distribution_of_hobbies_train_test.iterrows()):\n",
        "  train_value = row[\"Train\"]\n",
        "  test_value = row[\"Test\"]\n",
        "  sum_value = train_value + test_value\n",
        "  plt.text(x=sum_value+1 , y =i , s=f\"{int(train_value)}+{int(test_value)}={int(sum_value)}\" , fontdict=dict(fontsize=10))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "e87w3nOWnUGH",
        "outputId": "491be6a8-3461-4d4f-e4f0-ae72822a2a07"
      },
      "source": [
        "y.sum(axis=1).plot.hist(title='Histogram of the number of hobbies for each person')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f582701d5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72fDWLw4mk4B"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebGiWvLqlQFt"
      },
      "source": [
        "# Base Classifiers ( dict format --> (name, func) : params )\n",
        "base_models = {\n",
        "    (\"Decision_Tree\", DecisionTreeClassifier) : {'min_samples_split':range(2,5) , 'min_samples_leaf':range(1,4),'min_weight_fraction_leaf':[0.0,0.5],'random_state':[seed]},\n",
        "    (\"Extra_Trees\", ExtraTreesClassifier) : {'n_estimators':range(90,120,10),'min_samples_split':range(2,5) , 'min_samples_leaf':range(1,4),'n_jobs':[-1],'random_state':[seed]},\n",
        "    (\"Random_Forest\", RandomForestClassifier) :{'n_estimators':range(90,120,10),'min_samples_split':range(2,5),'min_samples_leaf':range(1,4),'n_jobs':[-1],'random_state':[seed]},\n",
        "    (\"MLP\", MLPClassifier) : {'hidden_layer_sizes': [(128,64,32),(64,32),(64)],'alpha':[1e-3, 1e-2, 1e-1], 'max_iter': [2000],'random_state':[seed]},\n",
        "    (\"Ridge\", RidgeClassifierCV) : {'fit_intercept':[True]}\n",
        "}\n",
        "\n",
        "base_models_with_errors = {\n",
        "    # Error: No neighbors found for test samples array (need to increase the radius size to 20, only can run)\n",
        "    (\"Radius_Neighbours\", RadiusNeighborsClassifier) : {'radius':[1.0,1.5,2.0],'leaf_size':range(20,40),'p':range(1,3)},\n",
        "}\n",
        "\n",
        "# Adaptation approaches\n",
        "adapt_models = {\n",
        "    (\"Binary_Relevance_kNN_A\", BRkNNaClassifier) : {'k': range(1,3)},\n",
        "    (\"Binary_Relevance_kNN_B\", BRkNNbClassifier) : {'k': range(1,3)},\n",
        "    (\"Multi-Label_KNN\", MLkNN) : {'k': range(1,3), 's': [0.5, 0.7, 1.0]},\n",
        "    (\"ARAM_Neural_Network\", MLARAM) : {'threshold':[0.05], 'vigilance':[0.95]},\n",
        "    (\"Twin_SVM\", MLTSVM) : {'c_k': [2**i for i in range(-5, 5, 2)]} # need sparse input\n",
        "}\n",
        "\n",
        "# Problem Transformation\n",
        "problem_transform = {\n",
        "    \"Binary_Relevance\" : BinaryRelevance,\n",
        "    \"Classifier_Chain\" : ClassifierChain,\n",
        "    # \"Label_Powerset\" : LabelPowerset # too many output because 2^20 = 1048576\n",
        "}\n",
        "\n",
        "# Ensembles of Classifiers\n",
        "emsemble_methods = {\n",
        "    \"Distinct_Random k-labtest\" : RakelD,\n",
        "    \"Overlapping_Random_k-labtest\" : RakelO,\n",
        "    \"Label_Space_Partitoning\" : LabelSpacePartitioningClassifier,\n",
        "    \"Majoity_Voting\" : MajorityVotingClassifier\n",
        "}\n",
        "# Multi-label embeddings (KIV)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK2OVicp3RRN"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poag9j9Y3UbR"
      },
      "source": [
        "# Hyperparameters Tuning\n",
        "num_of_kfold_splits = 5"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPrPDLJ_sEZJ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBR9K5X1hhUX"
      },
      "source": [
        "### Adaptation approaches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw7j6Fj5hgOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1376fde-1b4c-4349-a3e9-58592c7a7808"
      },
      "source": [
        "results = {}\n",
        "scoring = 'f1_micro'\n",
        "y_sparse = sparse.csr_matrix(y_train)\n",
        "x_sparse = sparse.csr_matrix(x_train)\n",
        "for (model_name, model), params in adapt_models.items():\n",
        "  kfold = KFold(n_splits=num_of_kfold_splits, random_state=None)\n",
        "  clf = GridSearchCV(model(), params, cv=kfold, n_jobs=-1, scoring=scoring) # n_jobs=-1, << this cause error for some reason...\n",
        "  if model_name == \"Twin_SVM\": # this model need sparse input\n",
        "    clf.fit(x_sparse, y_sparse)\n",
        "  else:\n",
        "    clf.fit(x_train, y_train)\n",
        "  results[model_name] = clf\n",
        "  print(model_name,clf.best_score_)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binary_Relevance_kNN_A 0.499234844568685\n",
            "Binary_Relevance_kNN_B 0.2546153913758995\n",
            "Multi-Label_KNN 0.5008165166572858\n",
            "ARAM_Neural_Network 0.4984658444775036\n",
            "Twin_SVM 0.5529060168298685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPTInTnWiJ7H"
      },
      "source": [
        "### Problem Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuFCZquVjYFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd6ac21-892f-46c4-b2b0-e4017a16943c"
      },
      "source": [
        "scoring = 'f1_micro'\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=0.2, random_state=seed)\n",
        "# Random forest and ExtraTrees takes about 20 minutes each, if dw to wait, can just comment out these 2 algo in the dict above\n",
        "for strategy_name, strategy in problem_transform.items():\n",
        "  for (model_name, model), params in base_models.items():\n",
        "    parameters = {}\n",
        "    for param_name, param_value in params.items():\n",
        "      parameters[\"classifier__\"+param_name] = param_value\n",
        "    kfold = KFold(n_splits=num_of_kfold_splits, random_state=None) \n",
        "    clf = GridSearchCV(strategy(classifier=model()), parameters, cv=kfold, n_jobs=-1, scoring=scoring) # n_jobs=-1, << this cause error for some reason...\n",
        "    clf.fit(x_train, y_train)\n",
        "    results[f\"{strategy_name}_{model_name}\"] = clf\n",
        "    print(f\"{strategy_name}_{model_name}\",clf.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binary_Relevance_Decision_Tree 0.5185168368647163\n",
            "Binary_Relevance_Extra_Trees 0.5354170812531904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25CkOfQQkibn"
      },
      "source": [
        "### Ensembles of Classifiers (Under reconstruction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55caHiBW-xaB"
      },
      "source": [
        "#### Adaptation approaches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42qfHvzV53dB"
      },
      "source": [
        "def convertToParamsForProblemTransformation(base_models):\n",
        "  parameters = []\n",
        "  for (model_name, model), params in base_models.items():\n",
        "    parameter = {}\n",
        "    parameter[\"classifier\"] = model()\n",
        "    for param_name, param_value in params.items():\n",
        "      paramter[\"classifier__\"+param_name] = param_value\n",
        "    parameters.append(parameter)\n",
        "\n",
        "  return paramters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HhSmHPUkh7A"
      },
      "source": [
        "scoring = 'f1_micro'\n",
        "for emsemble_name, emsemble_method in emsemble_methods.items():\n",
        "  for strategy_name, strategy in problem_transform.items():\n",
        "    for base_model_name, base_model in base_models.items():\n",
        "      kfold = KFold(n_splits=num_of_kfold_splits, random_state=seed)\n",
        "      model = strategy(\n",
        "              classifier = base_model(),\n",
        "              require_dense = [False, True] # depens on the data is sparse or dense\n",
        "      )\n",
        "      cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, n_jobs=-1, scoring=scoring)\n",
        "      results.append(cv_results)\n",
        "      names.append(model_name)\n",
        "      msg = \"%s: %f (%f)\" % (model_name, cv_results.mean(), cv_results.std())\n",
        "      print(msg)\n",
        "      classifier = MajorityVotingClassifier(\n",
        "    clusterer = FixedLabelSpaceClusterer(clusters = [[1,3,4], [0, 2, 5]]),\n",
        "    classifier = ClassifierChain(classifier=GaussianNB())\n",
        ")\n",
        "classifier.fit(X_train,y_train)\n",
        "predictions = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLhMB0d07NY3"
      },
      "source": [
        "classifier = MajorityVotingClassifier(\n",
        "    clusterer = FixedLabelSpaceClusterer(clusters = [[1,3,4], [0, 2, 5]]),\n",
        "    classifier = ClassifierChain(classifier=GaussianNB())\n",
        ")\n",
        "classifier.fit(X_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvWdCMwxmfLx"
      },
      "source": [
        "# Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHuyET4zxwoy"
      },
      "source": [
        "def display_evaluation_result(results, y, x_test, y_test, distribution_of_hobbies_train_test, f1_average = \"micro\"):\n",
        "  result_table = []\n",
        "  for model_name, model in results.items():\n",
        "    y_pred = model.predict(x_test)\n",
        "    score = f1_score(y_test, y_pred, average=f1_average)\n",
        "    score_by_class = f1_score(y_test, y_pred, average=None, zero_division=0)\n",
        "    result_table.append([score]+score_by_class.tolist())\n",
        "\n",
        "  # f1 score evaluation result overall and by class in percentage \n",
        "  # 0 means no True Positive at all or there is no example of that class in the y_text at all\n",
        "  result_table_df = pd.DataFrame(result_table, columns=[\"Overall\"]+y.columns.tolist(), index=results.keys()) * 100\n",
        "  result_table_df.sort_values(by='Overall', inplace=True, ascending=False)\n",
        "\n",
        "  # arrange the columns according to the frequency of each hobbies in the test set\n",
        "  sorted_columns = distribution_of_hobbies_train_test[\"Test\"].sort_values(ascending=False).index.tolist()\n",
        "  modified_column_names = [column + \"(\" + str(int(distribution_of_hobbies_train_test.loc[column,\"Test\"]))+\")\" for column in sorted_columns]\n",
        "  result_table_df = result_table_df[[\"Overall\"] + sorted_columns] # sort the columns by the frequency of each hobbies in the test set \n",
        "  result_table_df.columns = [[\"Overall\"] + modified_column_names] # add the frequency of each hobbies in the test set in the column name\n",
        "  return result_table_df\n",
        "\n",
        "display_evaluation_result(results, y, x_test, y_test, distribution_of_hobbies_train_test, f1_average = \"micro\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aiu3zGULOA9s"
      },
      "source": [
        "# Outlier Removal\n",
        "https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXc9b3Q7ODfd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP1k4bwaiAaw"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG2f817ktGJg"
      },
      "source": [
        "### Chi Square Analysis\n",
        "https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "Fm_P4vKEh_cT",
        "outputId": "a30a314c-bbea-4296-c8e0-9835366368e0"
      },
      "source": [
        "# label encoding is used instead of one-hot encoding because one-hot encoding will create many features for one question\n",
        "# but label encoding is able to perform chi-square test between a single question as a whole and the hobby  \n",
        "x_df, y_df = label_encoding(df_cleaned)\n",
        "# only evaluate on train data to prevent data leakage\n",
        "x_train_label_encoded, _, y_train, _ = train_test_split(x_df.to_numpy(), y_df.to_numpy(), test_size=0.2, random_state=seed)\n",
        "chi2_result = chi2_analysis(x_train_label_encoded, x_df, y_train)\n",
        "chi2_result"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Gender:</th>\n",
              "      <td>3.770253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your favorite color?</th>\n",
              "      <td>2.721663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest.</th>\n",
              "      <td>1.865759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)</th>\n",
              "      <td>1.262605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Choose a pet which you prefer to keep.</th>\n",
              "      <td>1.237745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>When you retire, you'd like to live...</th>\n",
              "      <td>1.140896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How confident are you in your own abilities?</th>\n",
              "      <td>1.047536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you enjoy socializing with large groups of people?</th>\n",
              "      <td>1.025456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you like to sit in front of a computer for long hours?</th>\n",
              "      <td>0.964861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you organize your schedule well?</th>\n",
              "      <td>0.894733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What boosts your confidence ?</th>\n",
              "      <td>0.873657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you enjoy challenges?</th>\n",
              "      <td>0.590494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are you a perfectionist?</th>\n",
              "      <td>0.565545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What do you worry more about the most?</th>\n",
              "      <td>0.543666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you have lot of patience?</th>\n",
              "      <td>0.542080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How creative of a person do you think you are?</th>\n",
              "      <td>0.452276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your current occupation?</th>\n",
              "      <td>0.429382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your favorite time of the day?</th>\n",
              "      <td>0.395978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I prefer to spend my money on....</th>\n",
              "      <td>0.354823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How logical of a person do you think you are?</th>\n",
              "      <td>0.322900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Would you prefer to engage your brain more than your body?</th>\n",
              "      <td>0.259857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you enjoy making others happy?</th>\n",
              "      <td>0.229642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Would you rather visit the future or the past?</th>\n",
              "      <td>0.175438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are you a trusting person?</th>\n",
              "      <td>0.159637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Can you understand others' perspectives and feelings?</th>\n",
              "      <td>0.091788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are you a curious person?</th>\n",
              "      <td>0.083091</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                           0\n",
              "Gender:                                             3.770253\n",
              "What is your favorite color?                        2.721663\n",
              "How do you organize your thoughts? Please pick ...  1.865759\n",
              "What is your learning style? (Pick one that ben...  1.262605\n",
              "Choose a pet which you prefer to keep.              1.237745\n",
              "When you retire, you'd like to live...              1.140896\n",
              "How confident are you in your own abilities?        1.047536\n",
              "Do you enjoy socializing with large groups of p...  1.025456\n",
              "Do you like to sit in front of a computer for l...  0.964861\n",
              "Do you organize your schedule well?                 0.894733\n",
              "What boosts your confidence ?                       0.873657\n",
              "Do you enjoy challenges?                            0.590494\n",
              "Are you a perfectionist?                            0.565545\n",
              "What do you worry more about the most?              0.543666\n",
              "Do you have lot of patience?                        0.542080\n",
              "How creative of a person do you think you are?      0.452276\n",
              "What is your current occupation?                    0.429382\n",
              "What is your favorite time of the day?              0.395978\n",
              "I prefer to spend my money on....                   0.354823\n",
              "How logical of a person do you think you are?       0.322900\n",
              "Would you prefer to engage your brain more than...  0.259857\n",
              "Do you enjoy making others happy?                   0.229642\n",
              "Would you rather visit the future or the past?      0.175438\n",
              "Are you a trusting person?                          0.159637\n",
              "Can you understand others' perspectives and fee...  0.091788\n",
              "Are you a curious person?                           0.083091"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKBiDhjAtB9D"
      },
      "source": [
        "##### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6bFvie1ugfe",
        "outputId": "9acd80f0-804f-4764-e31d-9d13a731401f"
      },
      "source": [
        "params = base_models[(\"Extra_Trees\", ExtraTreesClassifier)]\n",
        "params = {\"classifier__\"+param_name:param for param_name, param in params.items()}\n",
        "params[\"classifier\"] = [ExtraTreesClassifier()]\n",
        "scoring = 'f1_micro'\n",
        "\n",
        "results = {}\n",
        "for i in range(len(chi2_result.index)):\n",
        "  best_k_features = select_best_k_features(chi2_result, k=i+1)\n",
        "  x = filter_features(best_k_features, df_norm)\n",
        "  x_numpy, y_numpy = x.to_numpy(), y.to_numpy()\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=0.2, random_state=seed)\n",
        "  clf = GridSearchCV(BinaryRelevance(), params, cv=5, n_jobs=-1, scoring=scoring)\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  score = f1_score(y_test, y_pred, average=\"micro\")\n",
        "  print(\"Number of best k features:\", len(best_k_features), \"score:\",score)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of best k features: 1 score: 0.5245901639344261\n",
            "Number of best k features: 2 score: 0.5685279187817259\n",
            "Number of best k features: 3 score: 0.4973544973544973\n",
            "Number of best k features: 4 score: 0.541871921182266\n",
            "Number of best k features: 5 score: 0.5358851674641147\n",
            "Number of best k features: 6 score: 0.5980392156862745\n",
            "Number of best k features: 7 score: 0.6190476190476191\n",
            "Number of best k features: 8 score: 0.5853658536585366\n",
            "Number of best k features: 9 score: 0.5970149253731343\n",
            "Number of best k features: 10 score: 0.6176470588235294\n",
            "Number of best k features: 11 score: 0.6336633663366337\n",
            "Number of best k features: 12 score: 0.6467661691542289\n",
            "Number of best k features: 13 score: 0.6220095693779903\n",
            "Number of best k features: 14 score: 0.6538461538461539\n",
            "Number of best k features: 15 score: 0.624390243902439\n",
            "Number of best k features: 16 score: 0.6403940886699508\n",
            "Number of best k features: 17 score: 0.6538461538461539\n",
            "Number of best k features: 18 score: 0.6467661691542289\n",
            "Number of best k features: 19 score: 0.6336633663366337\n",
            "Number of best k features: 20 score: 0.653658536585366\n",
            "Number of best k features: 21 score: 0.6310679611650486\n",
            "Number of best k features: 22 score: 0.6048780487804878\n",
            "Number of best k features: 23 score: 0.6567164179104478\n",
            "Number of best k features: 24 score: 0.626865671641791\n",
            "Number of best k features: 25 score: 0.6310679611650486\n",
            "Number of best k features: 26 score: 0.6280193236714975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3XEZEvymjl8",
        "outputId": "fb273de2-d03d-41f8-8725-5b8fde74ca3c"
      },
      "source": [
        "# 23 features has the best result\n",
        "best_k_features = select_best_k_features(chi2_result, k=23)\n",
        "best_k_features"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Gender: ',\n",
              " 'What is your favorite color?',\n",
              " 'How do you organize your thoughts? Please pick whichever is closest.',\n",
              " 'What is your learning style? (Pick one that benefit you the most)',\n",
              " 'Choose a pet which you prefer to keep.',\n",
              " \"When you retire, you'd like to live...\",\n",
              " 'How confident are you in your own abilities?',\n",
              " 'Do you enjoy socializing with large groups of people?',\n",
              " 'Do you like to sit in front of a computer for long hours?',\n",
              " 'Do you organize your schedule well?',\n",
              " 'What boosts your confidence ? ',\n",
              " 'Do you enjoy challenges?',\n",
              " 'Are you a perfectionist?',\n",
              " 'What do you worry more about the most?',\n",
              " 'Do you have lot of patience?',\n",
              " 'How creative of a person do you think you are?',\n",
              " 'What is your current occupation?',\n",
              " 'What is your favorite time of the day?',\n",
              " 'I prefer to spend my money on....',\n",
              " 'How logical of a person do you think you are?',\n",
              " 'Would you prefer to engage your brain more than your body?',\n",
              " 'Do you enjoy making others happy?',\n",
              " 'Would you rather visit the future or the past?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "Gdl2urH2sseB",
        "outputId": "54539ca8-a67e-40d1-d810-bf8500ea3e6e"
      },
      "source": [
        "# 23 features\n",
        "display_evaluation_result(results, y, x_test, y_test, distribution_of_hobbies_train_test, f1_average = \"micro\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Overall</th>\n",
              "      <th>Games(23)</th>\n",
              "      <th>Sports and Outdoors(22)</th>\n",
              "      <th>Spiritual and Mental(22)</th>\n",
              "      <th>Performing Arts(15)</th>\n",
              "      <th>Arts and Craft(8)</th>\n",
              "      <th>Rejuvenation(6)</th>\n",
              "      <th>Food and Drinks(6)</th>\n",
              "      <th>Collecting(4)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Extra_Trees</th>\n",
              "      <td>65.671642</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>73.913043</td>\n",
              "      <td>79.245283</td>\n",
              "      <td>46.153846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_MLP</th>\n",
              "      <td>65.116279</td>\n",
              "      <td>85.106383</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>81.632653</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>57.142857</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_MLP</th>\n",
              "      <td>64.220183</td>\n",
              "      <td>80.851064</td>\n",
              "      <td>76.595745</td>\n",
              "      <td>83.333333</td>\n",
              "      <td>34.482759</td>\n",
              "      <td>58.823529</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Extra_Trees</th>\n",
              "      <td>63.725490</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>73.913043</td>\n",
              "      <td>79.245283</td>\n",
              "      <td>44.444444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Random_Forest</th>\n",
              "      <td>62.745098</td>\n",
              "      <td>81.632653</td>\n",
              "      <td>73.913043</td>\n",
              "      <td>76.363636</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Ridge</th>\n",
              "      <td>62.500000</td>\n",
              "      <td>77.551020</td>\n",
              "      <td>75.555556</td>\n",
              "      <td>79.245283</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Random_Forest</th>\n",
              "      <td>61.538462</td>\n",
              "      <td>72.340426</td>\n",
              "      <td>72.340426</td>\n",
              "      <td>77.777778</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Ridge</th>\n",
              "      <td>60.869565</td>\n",
              "      <td>77.551020</td>\n",
              "      <td>75.555556</td>\n",
              "      <td>77.777778</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Decision_Tree</th>\n",
              "      <td>60.089686</td>\n",
              "      <td>74.193548</td>\n",
              "      <td>72.131148</td>\n",
              "      <td>72.131148</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Decision_Tree</th>\n",
              "      <td>60.089686</td>\n",
              "      <td>74.193548</td>\n",
              "      <td>72.131148</td>\n",
              "      <td>72.131148</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Twin_SVM</th>\n",
              "      <td>56.081081</td>\n",
              "      <td>78.571429</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>67.857143</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>48.275862</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>19.354839</td>\n",
              "      <td>11.764706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_A</th>\n",
              "      <td>54.867257</td>\n",
              "      <td>69.565217</td>\n",
              "      <td>62.222222</td>\n",
              "      <td>79.166667</td>\n",
              "      <td>42.424242</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>22.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ARAM_Neural_Network</th>\n",
              "      <td>54.148472</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>57.777778</td>\n",
              "      <td>76.923077</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>22.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Multi-Label_KNN</th>\n",
              "      <td>50.267380</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>48.648649</td>\n",
              "      <td>61.538462</td>\n",
              "      <td>29.629630</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_B</th>\n",
              "      <td>29.223744</td>\n",
              "      <td>61.538462</td>\n",
              "      <td>45.161290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.500000</td>\n",
              "      <td>29.268293</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>18.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Overall  ... Collecting(4)\n",
              "Binary_Relevance_Extra_Trees    65.671642  ...      0.000000\n",
              "Binary_Relevance_MLP            65.116279  ...      0.000000\n",
              "Classifier_Chain_MLP            64.220183  ...      0.000000\n",
              "Classifier_Chain_Extra_Trees    63.725490  ...      0.000000\n",
              "Binary_Relevance_Random_Forest  62.745098  ...      0.000000\n",
              "Classifier_Chain_Ridge          62.500000  ...      0.000000\n",
              "Classifier_Chain_Random_Forest  61.538462  ...      0.000000\n",
              "Binary_Relevance_Ridge          60.869565  ...      0.000000\n",
              "Binary_Relevance_Decision_Tree  60.089686  ...      0.000000\n",
              "Classifier_Chain_Decision_Tree  60.089686  ...      0.000000\n",
              "Twin_SVM                        56.081081  ...     11.764706\n",
              "Binary_Relevance_kNN_A          54.867257  ...     22.222222\n",
              "ARAM_Neural_Network             54.148472  ...     22.222222\n",
              "Multi-Label_KNN                 50.267380  ...     40.000000\n",
              "Binary_Relevance_kNN_B          29.223744  ...     18.750000\n",
              "\n",
              "[15 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aVEjdKRwDBu"
      },
      "source": [
        "### Recursive Feature Elimination (rfe)\n",
        "https://machinelearningmastery.com/rfe-feature-selection-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUq8Tc0Ydbit",
        "outputId": "66dc57ff-f965-4fe6-8a24-f942e37a468a"
      },
      "source": [
        "rfe_result = rfe_cv(x_train, y_train, x.columns, y.columns, LogisticRegression())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Hobby: Sports and Outdoors\n",
            "Best number of features: 11\n",
            "Score: 0.6797849462365592\n",
            "1 Gender: _Male\n",
            "21 Choose a pet which you prefer to keep._Horse\n",
            "25 Choose a pet which you prefer to keep._Tortoise\n",
            "40 What is your favorite color?_Blue\n",
            "50 What is your learning style? (Pick one that benefit you the most)_By reading an e-Book\n",
            "52 Do you enjoy challenges?\n",
            "55 Would you prefer to engage your brain more than your body?\n",
            "57 Are you a perfectionist?\n",
            "58 Are you a trusting person?\n",
            "59 Do you have lot of patience?\n",
            "64 How confident are you in your own abilities?\n",
            "\n",
            "Hobby: Games\n",
            "Best number of features: 10\n",
            "Score: 0.5944086021505377\n",
            "1 Gender: _Male\n",
            "4 What is your current occupation?_University student\n",
            "11 I prefer to spend my money on...._The latest fashion\n",
            "22 Choose a pet which you prefer to keep._I'm not a pet person\n",
            "31 What do you worry more about the most?_Money\n",
            "33 What do you worry more about the most?_Your family and friends\n",
            "35 When you retire, you'd like to live..._Exactly where I live now\n",
            "42 What is your favorite color?_Purple\n",
            "50 What is your learning style? (Pick one that benefit you the most)_By reading an e-Book\n",
            "61 Do you like to sit in front of a computer for long hours?\n",
            "\n",
            "Hobby: Spiritual and Mental\n",
            "Best number of features: 18\n",
            "Score: 0.6270967741935484\n",
            "1 Gender: _Male\n",
            "6 What boosts your confidence ? _Get the most/ special attention among the members\n",
            "8 What boosts your confidence ? _When you accomplish a project\n",
            "15 How do you organize your thoughts? Please pick whichever is closest._I write it down in my calendar\n",
            "17 Choose a pet which you prefer to keep._Cat\n",
            "24 Choose a pet which you prefer to keep._Snake\n",
            "30 Would you rather visit the future or the past?_The past\n",
            "31 What do you worry more about the most?_Money\n",
            "36 When you retire, you'd like to live..._In a hectic big city\n",
            "37 When you retire, you'd like to live..._In a small town\n",
            "43 What is your favorite color?_Red\n",
            "44 What is your favorite color?_White\n",
            "50 What is your learning style? (Pick one that benefit you the most)_By reading an e-Book\n",
            "52 Do you enjoy challenges?\n",
            "53 How creative of a person do you think you are?\n",
            "54 How logical of a person do you think you are?\n",
            "62 Do you enjoy making others happy?\n",
            "63 Can you understand others' perspectives and feelings?\n",
            "\n",
            "Hobby: Performing Arts\n",
            "Best number of features: 12\n",
            "Score: 0.6348387096774193\n",
            "1 Gender: _Male\n",
            "4 What is your current occupation?_University student\n",
            "8 What boosts your confidence ? _When you accomplish a project\n",
            "11 I prefer to spend my money on...._The latest fashion\n",
            "14 How do you organize your thoughts? Please pick whichever is closest._I talk to myself out loud\n",
            "31 What do you worry more about the most?_Money\n",
            "33 What do you worry more about the most?_Your family and friends\n",
            "35 When you retire, you'd like to live..._Exactly where I live now\n",
            "41 What is your favorite color?_Green\n",
            "43 What is your favorite color?_Red\n",
            "45 What is your favorite color?_Yellow\n",
            "51 Do you enjoy socializing with large groups of people?\n",
            "\n",
            "Hobby: Arts and Craft\n",
            "Best number of features: 3\n",
            "Score: 0.7649462365591397\n",
            "53 How creative of a person do you think you are?\n",
            "54 How logical of a person do you think you are?\n",
            "61 Do you like to sit in front of a computer for long hours?\n",
            "\n",
            "Hobby: Food and Drinks\n",
            "Best number of features: 1\n",
            "Score: 0.6929032258064517\n",
            "44 What is your favorite color?_White\n",
            "\n",
            "Hobby: Collecting\n",
            "Best number of features: 1\n",
            "Score: 0.8890322580645161\n",
            "17 Choose a pet which you prefer to keep._Cat\n",
            "\n",
            "Hobby: Rejuvenation\n",
            "Best number of features: 8\n",
            "Score: 0.9150537634408602\n",
            "3 What is your current occupation?_Unemployed\n",
            "4 What is your current occupation?_University student\n",
            "28 What is your favorite time of the day?_Night\n",
            "32 What do you worry more about the most?_The state of the world\n",
            "42 What is your favorite color?_Purple\n",
            "59 Do you have lot of patience?\n",
            "60 Do you organize your schedule well?\n",
            "64 How confident are you in your own abilities?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9GXqrMn51rR"
      },
      "source": [
        "##### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "kpvUp9Gh6RBn",
        "outputId": "5d7b3977-9cf4-4d5f-faaf-6b391bb7795a"
      },
      "source": [
        "params = base_models[(\"Extra_Trees\", ExtraTreesClassifier)]\n",
        "params = {\"classifier__\"+param_name:param for param_name, param in params.items()}\n",
        "params[\"classifier\"] = [ExtraTreesClassifier()]\n",
        "scoring = 'f1_micro'\n",
        "\n",
        "results = {}\n",
        "for i in range(len(rfe_result.index)):\n",
        "  best_k_features = select_best_k_features(rfe_result, k=i+1)\n",
        "  x = filter_features(best_k_features, df_norm)\n",
        "  x_numpy, y_numpy = x.to_numpy(), y.to_numpy()\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=0.2, random_state=seed)\n",
        "  clf = GridSearchCV(BinaryRelevance(), params, cv=5, n_jobs=-1, scoring=scoring)\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  score = f1_score(y_test, y_pred, average=\"micro\")\n",
        "  print(\"Number of best k features:\", len(best_k_features), \"score:\",score)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of best k features: 1 score: 0.5245901639344261\n",
            "Number of best k features: 2 score: 0.4659090909090909\n",
            "Number of best k features: 3 score: 0.59\n",
            "Number of best k features: 4 score: 0.5858585858585859\n",
            "Number of best k features: 5 score: 0.6091370558375634\n",
            "Number of best k features: 6 score: 0.5757575757575758\n",
            "Number of best k features: 7 score: 0.5700000000000001\n",
            "Number of best k features: 8 score: 0.5825242718446602\n",
            "Number of best k features: 9 score: 0.5911330049261084\n",
            "Number of best k features: 10 score: 0.5673076923076924\n",
            "Number of best k features: 11 score: 0.5853658536585366\n",
            "Number of best k features: 12 score: 0.6086956521739131\n",
            "Number of best k features: 13 score: 0.5990338164251208\n",
            "Number of best k features: 14 score: 0.6086956521739131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3be69e0fef6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBinaryRelevance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"micro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0KUzp2DuraX",
        "outputId": "cdb33224-eb69-4017-a260-3e483b7ccc25"
      },
      "source": [
        "best_k_features = select_best_k_features(rfe_analysis, k=20)\n",
        "best_k_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Gender: ',\n",
              " 'Do you enjoy challenges?',\n",
              " 'Are you a trusting person?',\n",
              " 'Would you rather visit the future or the past?',\n",
              " 'How do you organize your thoughts? Please pick whichever is closest.',\n",
              " 'What do you worry more about the most?',\n",
              " 'How creative of a person do you think you are?',\n",
              " 'Do you have lot of patience?',\n",
              " 'How confident are you in your own abilities?',\n",
              " 'What is your favorite color?',\n",
              " \"When you retire, you'd like to live...\",\n",
              " 'Are you a perfectionist?',\n",
              " 'Do you enjoy socializing with large groups of people?',\n",
              " 'Do you like to sit in front of a computer for long hours?',\n",
              " 'What is your favorite time of the day?',\n",
              " 'What is your learning style? (Pick one that benefit you the most)',\n",
              " 'I prefer to spend my money on....',\n",
              " 'Do you organize your schedule well?',\n",
              " 'What boosts your confidence ? ',\n",
              " 'Would you prefer to engage your brain more than your body?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMaEigoD52Sk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "40057114-9cfd-4d96-e026-83c2d92252f6"
      },
      "source": [
        "# 20 features\n",
        "display_evaluation_result(results, y, x_test, y_test, distribution_of_hobbies_train_test, f1_average = \"micro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Overall</th>\n",
              "      <th>Playing computer games(19)</th>\n",
              "      <th>Reading(18)</th>\n",
              "      <th>Exercising(13)</th>\n",
              "      <th>Cooking(12)</th>\n",
              "      <th>Singing(10)</th>\n",
              "      <th>Badminton(9)</th>\n",
              "      <th>Team sports(7)</th>\n",
              "      <th>Writing(6)</th>\n",
              "      <th>Playing board games(6)</th>\n",
              "      <th>Dancing(5)</th>\n",
              "      <th>Painting(5)</th>\n",
              "      <th>Gardening(4)</th>\n",
              "      <th>Puzzles(3)</th>\n",
              "      <th>Sleeping(3)</th>\n",
              "      <th>Collecting(2)</th>\n",
              "      <th>Watching TV series(2)</th>\n",
              "      <th>Watching movies(2)</th>\n",
              "      <th>Playing a musical instrument(1)</th>\n",
              "      <th>Fishing(1)</th>\n",
              "      <th>Listening to music(1)</th>\n",
              "      <th>Photography and Videography(0)</th>\n",
              "      <th>Crocheting(0)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Extra_Tree</th>\n",
              "      <td>37.762238</td>\n",
              "      <td>46.153846</td>\n",
              "      <td>52.380952</td>\n",
              "      <td>51.612903</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>26.086957</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>61.538462</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>44.444444</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Twin_SVM</th>\n",
              "      <td>37.021277</td>\n",
              "      <td>62.962963</td>\n",
              "      <td>61.538462</td>\n",
              "      <td>46.511628</td>\n",
              "      <td>48.888889</td>\n",
              "      <td>30.769231</td>\n",
              "      <td>27.027027</td>\n",
              "      <td>47.619048</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>31.250000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>8.695652</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Decision_Tree</th>\n",
              "      <td>36.496350</td>\n",
              "      <td>42.424242</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>21.052632</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>53.333333</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Decision_Tree</th>\n",
              "      <td>33.582090</td>\n",
              "      <td>42.424242</td>\n",
              "      <td>51.428571</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>37.037037</td>\n",
              "      <td>34.782609</td>\n",
              "      <td>57.142857</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>30.769231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_MLP</th>\n",
              "      <td>32.456140</td>\n",
              "      <td>56.410256</td>\n",
              "      <td>52.380952</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>38.095238</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Extra_Tree</th>\n",
              "      <td>31.799163</td>\n",
              "      <td>35.294118</td>\n",
              "      <td>63.157895</td>\n",
              "      <td>35.714286</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>37.500000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_MLP</th>\n",
              "      <td>31.279621</td>\n",
              "      <td>41.176471</td>\n",
              "      <td>48.780488</td>\n",
              "      <td>43.478261</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>37.500000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_A</th>\n",
              "      <td>31.250000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>26.086957</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>47.619048</td>\n",
              "      <td>23.529412</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Multi-Label_KNN</th>\n",
              "      <td>31.250000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>26.086957</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>47.619048</td>\n",
              "      <td>23.529412</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ARAM_Neural_Network</th>\n",
              "      <td>28.996283</td>\n",
              "      <td>37.837838</td>\n",
              "      <td>53.658537</td>\n",
              "      <td>30.769231</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>47.619048</td>\n",
              "      <td>10.526316</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>30.769231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Extra_Trees</th>\n",
              "      <td>28.723404</td>\n",
              "      <td>38.709677</td>\n",
              "      <td>56.521739</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Extra_Trees</th>\n",
              "      <td>27.027027</td>\n",
              "      <td>37.500000</td>\n",
              "      <td>57.777778</td>\n",
              "      <td>10.526316</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Ridge</th>\n",
              "      <td>26.943005</td>\n",
              "      <td>37.500000</td>\n",
              "      <td>60.869565</td>\n",
              "      <td>19.047619</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>23.529412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Random_Forest</th>\n",
              "      <td>25.842697</td>\n",
              "      <td>34.482759</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Ridge</th>\n",
              "      <td>24.598930</td>\n",
              "      <td>38.709677</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>23.529412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Random_Forest</th>\n",
              "      <td>23.076923</td>\n",
              "      <td>21.428571</td>\n",
              "      <td>62.745098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_B</th>\n",
              "      <td>2.343750</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.407407</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Overall  ... Crocheting(0)\n",
              "Classifier_Chain_Extra_Tree     37.762238  ...           0.0\n",
              "Twin_SVM                        37.021277  ...           0.0\n",
              "Classifier_Chain_Decision_Tree  36.496350  ...           0.0\n",
              "Binary_Relevance_Decision_Tree  33.582090  ...           0.0\n",
              "Binary_Relevance_MLP            32.456140  ...           0.0\n",
              "Binary_Relevance_Extra_Tree     31.799163  ...           0.0\n",
              "Classifier_Chain_MLP            31.279621  ...           0.0\n",
              "Binary_Relevance_kNN_A          31.250000  ...           0.0\n",
              "Multi-Label_KNN                 31.250000  ...           0.0\n",
              "ARAM_Neural_Network             28.996283  ...           0.0\n",
              "Binary_Relevance_Extra_Trees    28.723404  ...           0.0\n",
              "Classifier_Chain_Extra_Trees    27.027027  ...           0.0\n",
              "Binary_Relevance_Ridge          26.943005  ...           0.0\n",
              "Classifier_Chain_Random_Forest  25.842697  ...           0.0\n",
              "Classifier_Chain_Ridge          24.598930  ...           0.0\n",
              "Binary_Relevance_Random_Forest  23.076923  ...           0.0\n",
              "Binary_Relevance_kNN_B           2.343750  ...           0.0\n",
              "\n",
              "[17 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqOJDmN_GPAF"
      },
      "source": [
        "# Save and load model\n",
        "https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/#:~:text=Saving%20Your%20Model-,Save%20Your%20Model%20with%20pickle,it%20to%20make%20new%20predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt5ITlvFGRVy"
      },
      "source": [
        "import pickle\n",
        "# save the model to disk\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}