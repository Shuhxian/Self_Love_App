{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finding&Ranking.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgS7Ufel5p/juSt+KKyrtz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandontan99/Self_Love_App/blob/master/Finding%26Ranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF-yGJAauY3d"
      },
      "source": [
        "# Finding "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oQtKAiauhjc"
      },
      "source": [
        "* **MinMaxScalar** takes the minimum value in that column but one of our questions, no example picked 0 as their choice, so the scaling is different from other questions. Should we hard-coded 0 as our minimum value? (I have tried both with and without, it doesnt have any significant effect on the model performance)\n",
        "* I have tried **Recursive Feature Elimination (rfe)** with LogisticRegression as my estimator as well as the feature selection tool. However, it does not perform better than using chi square because the evaluation result usually 1-2% worse than chi-square. https://machinelearningmastery.com/rfe-feature-selection-in-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OpGtITAl9KV"
      },
      "source": [
        "# Classifier_Chain_Extra_Tree [f1_micro: 44.128114%] - 13 questions used as features only "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i23q7vfnfadE"
      },
      "source": [
        "*   Rank all the features using Chi-Squared correlation with the help of sklearn library (SelectKBest(chi2, k='all')) by averaging out the chi2 score of all the hobbies by features https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/\n",
        "*   The higher the value, the more correlated the question is relative to the hobbies\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Gender:</th>\n",
        "      <td>3.005050</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How do you organize your thoughts? Please pick whichever is closest.</th>\n",
        "      <td>2.354217</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Choose a pet which you prefer to keep.</th>\n",
        "      <td>1.662849</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What is your favorite color?</th>\n",
        "      <td>1.457257</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>I prefer to spend my money on....</th>\n",
        "      <td>1.082236</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>When you retire, you'd like to live...</th>\n",
        "      <td>1.074117</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you enjoy socializing with large groups of people?</th>\n",
        "      <td>0.807226</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What is your learning style? (Pick one that benefit you the most)</th>\n",
        "      <td>0.775461</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What boosts your confidence ?</th>\n",
        "      <td>0.759482</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What do you worry more about the most?</th>\n",
        "      <td>0.656682</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you like to sit in front of a computer for long hours?</th>\n",
        "      <td>0.572489</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you have lot of patience?</th>\n",
        "      <td>0.504721</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Would you rather visit the future or the past?</th>\n",
        "      <td>0.479577</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How confident are you in your own abilities?</th>\n",
        "      <td>0.432469</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Are you a perfectionist?</th>\n",
        "      <td>0.427847</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you organize your schedule well?</th>\n",
        "      <td>0.404172</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you enjoy challenges?</th>\n",
        "      <td>0.392193</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How creative of a person do you think you are?</th>\n",
        "      <td>0.385397</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Are you a trusting person?</th>\n",
        "      <td>0.372718</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What is your current occupation?</th>\n",
        "      <td>0.255158</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What is your favorite time of the day?</th>\n",
        "      <td>0.252841</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Can you understand others' perspectives and feelings?</th>\n",
        "      <td>0.250852</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How logical of a person do you think you are?</th>\n",
        "      <td>0.228929</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Would you prefer to engage your brain more than your body?</th>\n",
        "      <td>0.165099</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you enjoy making others happy?</th>\n",
        "      <td>0.154962</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Are you a curious person?</th>\n",
        "      <td>0.109949</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "* To determine the best number of features, Classifier_Chain_Extra_Tree algorithm is used to train on training set with 5 fold cross validation and evaluate the test set by adding the feature with the highest score in the remaining questions at each iteration of training and evaluation\n",
        "* The result shows that 13 best features has the best performance. \n",
        "<pre>Number of best k features: 1 score: 0.2903225806451613\n",
        "Number of best k features: 2 score: 0.24043715846994534\n",
        "Number of best k features: 3 score: 0.28837209302325584\n",
        "Number of best k features: 4 score: 0.32061068702290074\n",
        "Number of best k features: 5 score: 0.3320754716981132\n",
        "Number of best k features: 6 score: 0.3282442748091603\n",
        "Number of best k features: 7 score: 0.3103448275862069\n",
        "Number of best k features: 8 score: 0.2720000000000001\n",
        "Number of best k features: 9 score: 0.32608695652173914\n",
        "Number of best k features: 10 score: 0.35036496350364965\n",
        "Number of best k features: 11 score: 0.30434782608695654\n",
        "Number of best k features: 12 score: 0.35125448028673834\n",
        "Number of best k features: 13 score: 0.4412811387900356\n",
        "Number of best k features: 14 score: 0.2916666666666667\n",
        "Number of best k features: 15 score: 0.3392226148409894\n",
        "Number of best k features: 16 score: 0.3161512027491409\n",
        "Number of best k features: 17 score: 0.3003952569169961\n",
        "Number of best k features: 18 score: 0.3165467625899281\n",
        "Number of best k features: 19 score: 0.352059925093633\n",
        "Number of best k features: 20 score: 0.3821138211382114\n",
        "Number of best k features: 21 score: 0.32575757575757575\n",
        "Number of best k features: 22 score: 0.26415094339622636\n",
        "Number of best k features: 23 score: 0.25941422594142255\n",
        "Number of best k features: 24 score: 0.2783882783882784\n",
        "Number of best k features: 25 score: 0.36820083682008364\n",
        "Number of best k features: 26 score: 0.213953488372093\n",
        "</pre>\n",
        "* Therefore, these 13 features/questions are used to train all the available algorithms.\n",
        "<pre>['Gender: ',\n",
        " 'How do you organize your thoughts? Please pick whichever is closest.',\n",
        " 'Choose a pet which you prefer to keep.',\n",
        " 'What is your favorite color?',\n",
        " 'I prefer to spend my money on....',\n",
        " \"When you retire, you'd like to live...\",\n",
        " 'Do you enjoy socializing with large groups of people?',\n",
        " 'What is your learning style? (Pick one that benefit you the most)',\n",
        " 'What boosts your confidence ? ',\n",
        " 'What do you worry more about the most?',\n",
        " 'Do you like to sit in front of a computer for long hours?',\n",
        " 'Do you have lot of patience?',\n",
        " 'Would you rather visit the future or the past?']</pre>\n",
        "* The result of each of the algorithms evaluated on 20% of test set with the 13 features as below.\n",
        "* The \"Overall\" column is the f1_micro score of that algorithm  \n",
        "* the other column name indicates the hobby with the frequency of the hobby that the test set comprises of whereas each of the column values are calculated using f1_score by hobby and algorithm\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <th>Overall</th>\n",
        "      <th>Playing computer games(19)</th>\n",
        "      <th>Reading(18)</th>\n",
        "      <th>Exercising(13)</th>\n",
        "      <th>Cooking(12)</th>\n",
        "      <th>Singing(10)</th>\n",
        "      <th>Badminton(9)</th>\n",
        "      <th>Team sports(7)</th>\n",
        "      <th>Writing(6)</th>\n",
        "      <th>Playing board games(6)</th>\n",
        "      <th>Dancing(5)</th>\n",
        "      <th>Painting(5)</th>\n",
        "      <th>Gardening(4)</th>\n",
        "      <th>Puzzles(3)</th>\n",
        "      <th>Sleeping(3)</th>\n",
        "      <th>Collecting(2)</th>\n",
        "      <th>Watching TV series(2)</th>\n",
        "      <th>Watching movies(2)</th>\n",
        "      <th>Playing a musical instrument(1)</th>\n",
        "      <th>Fishing(1)</th>\n",
        "      <th>Listening to music(1)</th>\n",
        "      <th>Photography and Videography(0)</th>\n",
        "      <th>Crocheting(0)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Extra_Tree</th>\n",
        "      <td>44.128114</td>\n",
        "      <td>57.142857</td>\n",
        "      <td>69.767442</td>\n",
        "      <td>51.851852</td>\n",
        "      <td>66.666667</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>60.000000</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>66.666667</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Twin_SVM</th>\n",
        "      <td>36.812144</td>\n",
        "      <td>66.666667</td>\n",
        "      <td>64.285714</td>\n",
        "      <td>46.511628</td>\n",
        "      <td>43.478261</td>\n",
        "      <td>37.209302</td>\n",
        "      <td>17.647059</td>\n",
        "      <td>46.153846</td>\n",
        "      <td>32.258065</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>37.500000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>23.529412</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_kNN_A</th>\n",
        "      <td>35.460993</td>\n",
        "      <td>54.054054</td>\n",
        "      <td>62.222222</td>\n",
        "      <td>34.782609</td>\n",
        "      <td>32.000000</td>\n",
        "      <td>45.454545</td>\n",
        "      <td>11.764706</td>\n",
        "      <td>46.153846</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>14.285714</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Multi-Label_KNN</th>\n",
        "      <td>35.460993</td>\n",
        "      <td>54.054054</td>\n",
        "      <td>62.222222</td>\n",
        "      <td>34.782609</td>\n",
        "      <td>32.000000</td>\n",
        "      <td>45.454545</td>\n",
        "      <td>11.764706</td>\n",
        "      <td>46.153846</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>14.285714</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Extra_Trees</th>\n",
        "      <td>35.406699</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>63.636364</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>15.384615</td>\n",
        "      <td>37.500000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ARAM_Neural_Network</th>\n",
        "      <td>35.251799</td>\n",
        "      <td>59.459459</td>\n",
        "      <td>62.222222</td>\n",
        "      <td>32.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>45.454545</td>\n",
        "      <td>12.500000</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>42.857143</td>\n",
        "      <td>15.384615</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>35.294118</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_MLP</th>\n",
        "      <td>34.666667</td>\n",
        "      <td>57.142857</td>\n",
        "      <td>57.142857</td>\n",
        "      <td>37.037037</td>\n",
        "      <td>23.529412</td>\n",
        "      <td>30.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Decision_Tree</th>\n",
        "      <td>32.974910</td>\n",
        "      <td>43.750000</td>\n",
        "      <td>55.813953</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>42.105263</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>10.526316</td>\n",
        "      <td>61.538462</td>\n",
        "      <td>26.666667</td>\n",
        "      <td>14.285714</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_MLP</th>\n",
        "      <td>32.500000</td>\n",
        "      <td>51.428571</td>\n",
        "      <td>54.545455</td>\n",
        "      <td>38.709677</td>\n",
        "      <td>21.052632</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Extra_Tree</th>\n",
        "      <td>31.501832</td>\n",
        "      <td>51.428571</td>\n",
        "      <td>60.000000</td>\n",
        "      <td>24.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>23.529412</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Random_Forest</th>\n",
        "      <td>30.687831</td>\n",
        "      <td>56.250000</td>\n",
        "      <td>56.521739</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>14.285714</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Ridge</th>\n",
        "      <td>29.850746</td>\n",
        "      <td>45.161290</td>\n",
        "      <td>61.224490</td>\n",
        "      <td>32.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Decision_Tree</th>\n",
        "      <td>29.411765</td>\n",
        "      <td>45.714286</td>\n",
        "      <td>51.162791</td>\n",
        "      <td>46.666667</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>12.500000</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>12.500000</td>\n",
        "      <td>12.500000</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Extra_Trees</th>\n",
        "      <td>29.145729</td>\n",
        "      <td>43.750000</td>\n",
        "      <td>60.465116</td>\n",
        "      <td>27.272727</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>35.294118</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Random_Forest</th>\n",
        "      <td>28.108108</td>\n",
        "      <td>48.484848</td>\n",
        "      <td>51.063830</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>37.500000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Ridge</th>\n",
        "      <td>26.041667</td>\n",
        "      <td>43.750000</td>\n",
        "      <td>58.333333</td>\n",
        "      <td>19.047619</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>23.529412</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_kNN_B</th>\n",
        "      <td>2.836879</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>5.0</td>\n",
        "      <td>50.0</td>\n",
        "      <td>7.142857</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbMlxO4smI_V"
      },
      "source": [
        "# Twin_SVM [f1_micro: 39.893617%] - filter out some least selected hobbies + 20 questions used as features only "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC3lF5ZMoE3k"
      },
      "source": [
        "* Remove the hobbies that have only 9 or less people selected\n",
        "* Remove the example that has no hobby selected\n",
        "* The table below shows the remaining data:\n",
        "<img src=\"data:image/png;base64,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%0A\">\n",
        "\n",
        "* Rank all the features using Chi-Squared correlation with the help of sklearn library (SelectKBest(chi2, k='all')) by averaging out the chi2 score of all the hobbies by features https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/\n",
        "* The higher the value, the more correlated the question is relative to the hobbies\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Gender:</th>\n",
        "      <td>3.426719</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How do you organize your thoughts? Please pick whichever is closest.</th>\n",
        "      <td>3.052265</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Choose a pet which you prefer to keep.</th>\n",
        "      <td>1.408217</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>I prefer to spend my money on....</th>\n",
        "      <td>1.394394</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What is your favorite color?</th>\n",
        "      <td>1.330150</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>When you retire, you'd like to live...</th>\n",
        "      <td>1.164201</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you enjoy socializing with large groups of people?</th>\n",
        "      <td>1.045551</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What boosts your confidence ?</th>\n",
        "      <td>0.983950</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you like to sit in front of a computer for long hours?</th>\n",
        "      <td>0.801735</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What do you worry more about the most?</th>\n",
        "      <td>0.526888</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Are you a perfectionist?</th>\n",
        "      <td>0.511296</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What is your learning style? (Pick one that benefit you the most)</th>\n",
        "      <td>0.488092</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you enjoy challenges?</th>\n",
        "      <td>0.473142</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How creative of a person do you think you are?</th>\n",
        "      <td>0.441478</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you have lot of patience?</th>\n",
        "      <td>0.433896</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you enjoy making others happy?</th>\n",
        "      <td>0.412462</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Would you rather visit the future or the past?</th>\n",
        "      <td>0.407291</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Are you a trusting person?</th>\n",
        "      <td>0.373623</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How logical of a person do you think you are?</th>\n",
        "      <td>0.359600</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Can you understand others' perspectives and feelings?</th>\n",
        "      <td>0.346542</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How confident are you in your own abilities?</th>\n",
        "      <td>0.335419</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What is your favorite time of the day?</th>\n",
        "      <td>0.289596</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you organize your schedule well?</th>\n",
        "      <td>0.260998</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Would you prefer to engage your brain more than your body?</th>\n",
        "      <td>0.224224</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What is your current occupation?</th>\n",
        "      <td>0.159675</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Are you a curious person?</th>\n",
        "      <td>0.148924</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "* To determine the best number of features, Twin SVM algorithm is used to train on training set with 5 fold cross validation and evaluate the test set by adding the feature with the highest score in the remaining questions at each iteration of training and evaluation\n",
        "The result shows that 20 best features has the best performance\n",
        "<pre>Number of best k features: 1 score: 0.3375\n",
        "Number of best k features: 2 score: 0.3181818181818182\n",
        "Number of best k features: 3 score: 0.34468937875751504\n",
        "Number of best k features: 4 score: 0.34782608695652173\n",
        "Number of best k features: 5 score: 0.3595505617977528\n",
        "Number of best k features: 6 score: 0.346938775510204\n",
        "Number of best k features: 7 score: 0.3395225464190981\n",
        "Number of best k features: 8 score: 0.38692098092643057\n",
        "Number of best k features: 9 score: 0.3945205479452055\n",
        "Number of best k features: 10 score: 0.37837837837837834\n",
        "Number of best k features: 11 score: 0.3891625615763547\n",
        "Number of best k features: 12 score: 0.3829787234042553\n",
        "Number of best k features: 13 score: 0.34726688102893893\n",
        "Number of best k features: 14 score: 0.34782608695652173\n",
        "Number of best k features: 15 score: 0.34782608695652173\n",
        "Number of best k features: 16 score: 0.35064935064935066\n",
        "Number of best k features: 17 score: 0.35008103727714746\n",
        "Number of best k features: 18 score: 0.3925729442970822\n",
        "Number of best k features: 19 score: 0.35008103727714746\n",
        "Number of best k features: 20 score: 0.39893617021276595\n",
        "Number of best k features: 21 score: 0.39164490861618795\n",
        "Number of best k features: 22 score: 0.35371900826446284\n",
        "Number of best k features: 23 score: 0.3548922056384743\n",
        "Number of best k features: 24 score: 0.35666666666666663\n",
        "Number of best k features: 25 score: 0.35294117647058826\n",
        "Number of best k features: 26 score: 0.357504215851602\n",
        "</pre>\n",
        "* Therefore, these 20 features/questions are used to train all the available algorithms\n",
        "<pre>['Gender: ',\n",
        " 'How do you organize your thoughts? Please pick whichever is closest.',\n",
        " 'Choose a pet which you prefer to keep.',\n",
        " 'I prefer to spend my money on....',\n",
        " 'What is your favorite color?',\n",
        " \"When you retire, you'd like to live...\",\n",
        " 'Do you enjoy socializing with large groups of people?',\n",
        " 'What boosts your confidence ? ',\n",
        " 'Do you like to sit in front of a computer for long hours?',\n",
        " 'What do you worry more about the most?',\n",
        " 'Are you a perfectionist?',\n",
        " 'What is your learning style? (Pick one that benefit you the most)',\n",
        " 'Do you enjoy challenges?',\n",
        " 'How creative of a person do you think you are?',\n",
        " 'Do you have lot of patience?',\n",
        " 'Do you enjoy making others happy?',\n",
        " 'Would you rather visit the future or the past?',\n",
        " 'Are you a trusting person?',\n",
        " 'How logical of a person do you think you are?',\n",
        " \"Can you understand others' perspectives and feelings?\"]</pre>\n",
        "* The result of each of the algorithms evaluated on 20% of test set with the 20 features as below.\n",
        "* The \"Overall\" column is the f1_micro score of that algorithm\n",
        "* The other column name indicates the hobby with the frequency of the hobby that the test set comprises of whereas each of the column values are calculated using f1_score by hobby and algorithm\n",
        " <table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <th>Overall</th>\n",
        "      <th>Reading(23)</th>\n",
        "      <th>Playing computer games(17)</th>\n",
        "      <th>Cooking(13)</th>\n",
        "      <th>Singing(11)</th>\n",
        "      <th>Exercising(8)</th>\n",
        "      <th>Team sports(7)</th>\n",
        "      <th>Puzzles(6)</th>\n",
        "      <th>Badminton(6)</th>\n",
        "      <th>Playing board games(5)</th>\n",
        "      <th>Dancing(4)</th>\n",
        "      <th>Painting(3)</th>\n",
        "      <th>Gardening(2)</th>\n",
        "      <th>Writing(2)</th>\n",
        "      <th>Collecting(1)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Twin_SVM</th>\n",
        "      <td>39.893617</td>\n",
        "      <td>66.666667</td>\n",
        "      <td>68.085106</td>\n",
        "      <td>54.054054</td>\n",
        "      <td>27.586207</td>\n",
        "      <td>32.432432</td>\n",
        "      <td>42.105263</td>\n",
        "      <td>41.666667</td>\n",
        "      <td>12.903226</td>\n",
        "      <td>32.000000</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>0.0</td>\n",
        "      <td>19.047619</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_MLP</th>\n",
        "      <td>39.408867</td>\n",
        "      <td>70.000000</td>\n",
        "      <td>58.823529</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>23.529412</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Decision_Tree</th>\n",
        "      <td>38.961039</td>\n",
        "      <td>66.666667</td>\n",
        "      <td>68.571429</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>47.619048</td>\n",
        "      <td>38.461538</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>10.526316</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Decision_Tree</th>\n",
        "      <td>38.888889</td>\n",
        "      <td>63.636364</td>\n",
        "      <td>64.864865</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>32.258065</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>30.769231</td>\n",
        "      <td>10.526316</td>\n",
        "      <td>21.052632</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Random_Forest</th>\n",
        "      <td>35.928144</td>\n",
        "      <td>65.217391</td>\n",
        "      <td>64.705882</td>\n",
        "      <td>26.666667</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>19.047619</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_MLP</th>\n",
        "      <td>35.779817</td>\n",
        "      <td>68.292683</td>\n",
        "      <td>54.545455</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>38.095238</td>\n",
        "      <td>32.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>26.666667</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Ridge</th>\n",
        "      <td>35.714286</td>\n",
        "      <td>76.595745</td>\n",
        "      <td>45.161290</td>\n",
        "      <td>23.529412</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>23.529412</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Extra_Trees</th>\n",
        "      <td>35.502959</td>\n",
        "      <td>69.565217</td>\n",
        "      <td>56.250000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>30.769231</td>\n",
        "      <td>26.086957</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Random_Forest</th>\n",
        "      <td>35.443038</td>\n",
        "      <td>75.555556</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Ridge</th>\n",
        "      <td>35.428571</td>\n",
        "      <td>68.181818</td>\n",
        "      <td>55.555556</td>\n",
        "      <td>37.500000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>17.391304</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Extra_Trees</th>\n",
        "      <td>35.365854</td>\n",
        "      <td>72.000000</td>\n",
        "      <td>45.161290</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Multi-Label_KNN</th>\n",
        "      <td>34.749035</td>\n",
        "      <td>57.777778</td>\n",
        "      <td>52.941176</td>\n",
        "      <td>41.666667</td>\n",
        "      <td>58.333333</td>\n",
        "      <td>41.379310</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>15.384615</td>\n",
        "      <td>26.666667</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_kNN_A</th>\n",
        "      <td>34.749035</td>\n",
        "      <td>57.777778</td>\n",
        "      <td>52.941176</td>\n",
        "      <td>41.666667</td>\n",
        "      <td>58.333333</td>\n",
        "      <td>41.379310</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>15.384615</td>\n",
        "      <td>26.666667</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Extra_Tree</th>\n",
        "      <td>34.615385</td>\n",
        "      <td>54.545455</td>\n",
        "      <td>51.428571</td>\n",
        "      <td>53.846154</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>21.428571</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>34.782609</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>12.500000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ARAM_Neural_Network</th>\n",
        "      <td>34.400000</td>\n",
        "      <td>65.217391</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>61.538462</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>15.384615</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>14.285714</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Extra_Tree</th>\n",
        "      <td>29.032258</td>\n",
        "      <td>63.414634</td>\n",
        "      <td>41.176471</td>\n",
        "      <td>19.047619</td>\n",
        "      <td>37.037037</td>\n",
        "      <td>27.272727</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>15.384615</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>30.769231</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_kNN_B</th>\n",
        "      <td>18.532819</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>10.526316</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>41.025641</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>29.268293</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>20.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>5.128205</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ_FjL1bqkXk"
      },
      "source": [
        "# Classifier_Chain_Extra_Tree [f1_micro: 43.609023%] - university students only + 12 questions used as features only "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbXENaTUrdIx"
      },
      "source": [
        "* Remove out the non-university student examples\n",
        "* Rank all the features using Chi-Squared correlation with the help of sklearn library (SelectKBest(chi2, k='all')) by averaging out the chi2 score of all the hobbies by features https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/\n",
        "* The higher the value, the more correlated the question is relative to the hobbies\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Choose a pet which you prefer to keep.</th>\n",
        "      <td>2.661988</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Gender:</th>\n",
        "      <td>2.526642</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How do you organize your thoughts? Please pick whichever is closest.</th>\n",
        "      <td>1.818323</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What is your favorite color?</th>\n",
        "      <td>1.804169</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>When you retire, you'd like to live...</th>\n",
        "      <td>1.097243</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>I prefer to spend my money on....</th>\n",
        "      <td>0.983913</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What is your learning style? (Pick one that benefit you the most)</th>\n",
        "      <td>0.739105</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you enjoy socializing with large groups of people?</th>\n",
        "      <td>0.691179</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you like to sit in front of a computer for long hours?</th>\n",
        "      <td>0.615506</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Would you rather visit the future or the past?</th>\n",
        "      <td>0.572487</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you have lot of patience?</th>\n",
        "      <td>0.471596</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What boosts your confidence ?</th>\n",
        "      <td>0.407423</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Are you a perfectionist?</th>\n",
        "      <td>0.402037</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What do you worry more about the most?</th>\n",
        "      <td>0.385930</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you organize your schedule well?</th>\n",
        "      <td>0.328513</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you enjoy challenges?</th>\n",
        "      <td>0.326454</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How creative of a person do you think you are?</th>\n",
        "      <td>0.300369</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>What is your favorite time of the day?</th>\n",
        "      <td>0.277673</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Are you a trusting person?</th>\n",
        "      <td>0.276116</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Can you understand others' perspectives and feelings?</th>\n",
        "      <td>0.204888</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How confident are you in your own abilities?</th>\n",
        "      <td>0.204255</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>How logical of a person do you think you are?</th>\n",
        "      <td>0.170137</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Do you enjoy making others happy?</th>\n",
        "      <td>0.155986</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Would you prefer to engage your brain more than your body?</th>\n",
        "      <td>0.154765</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Are you a curious person?</th>\n",
        "      <td>0.090893</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "* To determine the best number of features, Classifier_Chain_Extra_Tree algorithm is used to train on training set with 5 fold cross validation and evaluate the test set by adding the feature with the highest score in the remaining questions at each iteration of training and evaluation The result shows that 12 best features has the best performance\n",
        "<pre>Number of best k features: 1 score: 0.27586206896551724\n",
        "Number of best k features: 2 score: 0.25\n",
        "Number of best k features: 3 score: 0.33170731707317075\n",
        "Number of best k features: 4 score: 0.34108527131782945\n",
        "Number of best k features: 5 score: 0.4056939501779359\n",
        "Number of best k features: 6 score: 0.40433212996389895\n",
        "Number of best k features: 7 score: 0.3269961977186312\n",
        "Number of best k features: 8 score: 0.25974025974025977\n",
        "Number of best k features: 9 score: 0.36153846153846153\n",
        "Number of best k features: 10 score: 0.3939393939393939\n",
        "Number of best k features: 11 score: 0.36286919831223624\n",
        "Number of best k features: 12 score: 0.4360902255639098\n",
        "Number of best k features: 13 score: 0.34024896265560167\n",
        "Number of best k features: 14 score: 0.37121212121212127\n",
        "Number of best k features: 15 score: 0.33198380566801616\n",
        "Number of best k features: 16 score: 0.34657039711191334\n",
        "Number of best k features: 17 score: 0.3543307086614173\n",
        "Number of best k features: 18 score: 0.3240740740740741\n",
        "Number of best k features: 19 score: 0.40163934426229503\n",
        "Number of best k features: 20 score: 0.28682170542635654\n",
        "Number of best k features: 21 score: 0.32558139534883723\n",
        "Number of best k features: 22 score: 0.2965779467680608\n",
        "Number of best k features: 23 score: 0.31620553359683795\n",
        "Number of best k features: 24 score: 0.3688524590163934\n",
        "Number of best k features: 25 score: 0.3547169811320754\n",
        "</pre>\n",
        "* Therefore, these 12 features/questions are used to train all the available algorithms\n",
        "<pre>['Choose a pet which you prefer to keep.',\n",
        " 'Gender: ',\n",
        " 'How do you organize your thoughts? Please pick whichever is closest.',\n",
        " 'What is your favorite color?',\n",
        " \"When you retire, you'd like to live...\",\n",
        " 'I prefer to spend my money on....',\n",
        " 'What is your learning style? (Pick one that benefit you the most)',\n",
        " 'Do you enjoy socializing with large groups of people?',\n",
        " 'Do you like to sit in front of a computer for long hours?',\n",
        " 'Would you rather visit the future or the past?',\n",
        " 'Do you have lot of patience?',\n",
        " 'What boosts your confidence ? ']</pre>\n",
        "* The result of each of the algorithms evaluated on 20% of test set with the 12 features as below.\n",
        "* The \"Overall\" column is the f1_micro score of that algorithm\n",
        "* The other column name indicates the hobby with the frequency of the hobby that the test set comprises of whereas each of the column values are calculated using f1_score by hobby and algorithm\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <th>Overall</th>\n",
        "      <th>Reading(19)</th>\n",
        "      <th>Cooking(17)</th>\n",
        "      <th>Exercising(14)</th>\n",
        "      <th>Playing computer games(12)</th>\n",
        "      <th>Singing(10)</th>\n",
        "      <th>Playing board games(9)</th>\n",
        "      <th>Puzzles(8)</th>\n",
        "      <th>Painting(7)</th>\n",
        "      <th>Badminton(7)</th>\n",
        "      <th>Writing(6)</th>\n",
        "      <th>Dancing(5)</th>\n",
        "      <th>Team sports(3)</th>\n",
        "      <th>Gardening(2)</th>\n",
        "      <th>Sleeping(1)</th>\n",
        "      <th>Collecting(1)</th>\n",
        "      <th>Playing a musical instrument(1)</th>\n",
        "      <th>Watching movies(1)</th>\n",
        "      <th>Fishing(1)</th>\n",
        "      <th>Photography and Videography(1)</th>\n",
        "      <th>Watching TV series(0)</th>\n",
        "      <th>Listening to music(0)</th>\n",
        "      <th>Crocheting(0)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Extra_Tree</th>\n",
        "      <td>43.609023</td>\n",
        "      <td>63.414634</td>\n",
        "      <td>34.482759</td>\n",
        "      <td>56.000000</td>\n",
        "      <td>40.000000</td>\n",
        "      <td>59.259259</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>42.105263</td>\n",
        "      <td>42.857143</td>\n",
        "      <td>52.631579</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>66.666667</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Extra_Tree</th>\n",
        "      <td>42.914980</td>\n",
        "      <td>54.545455</td>\n",
        "      <td>57.142857</td>\n",
        "      <td>51.851852</td>\n",
        "      <td>44.444444</td>\n",
        "      <td>37.500000</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>52.631579</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>44.444444</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Twin_SVM</th>\n",
        "      <td>38.554217</td>\n",
        "      <td>69.387755</td>\n",
        "      <td>57.777778</td>\n",
        "      <td>63.414634</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>47.058824</td>\n",
        "      <td>41.176471</td>\n",
        "      <td>41.176471</td>\n",
        "      <td>32.258065</td>\n",
        "      <td>23.529412</td>\n",
        "      <td>26.666667</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>31.578947</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ARAM_Neural_Network</th>\n",
        "      <td>37.735849</td>\n",
        "      <td>71.428571</td>\n",
        "      <td>38.461538</td>\n",
        "      <td>51.851852</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>45.454545</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>14.285714</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>12.500000</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>75.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_MLP</th>\n",
        "      <td>37.500000</td>\n",
        "      <td>66.666667</td>\n",
        "      <td>27.272727</td>\n",
        "      <td>47.619048</td>\n",
        "      <td>45.454545</td>\n",
        "      <td>21.052632</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>14.285714</td>\n",
        "      <td>26.666667</td>\n",
        "      <td>15.384615</td>\n",
        "      <td>15.384615</td>\n",
        "      <td>54.545455</td>\n",
        "      <td>57.142857</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_kNN_A</th>\n",
        "      <td>36.226415</td>\n",
        "      <td>70.000000</td>\n",
        "      <td>46.666667</td>\n",
        "      <td>44.444444</td>\n",
        "      <td>24.000000</td>\n",
        "      <td>38.095238</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>37.500000</td>\n",
        "      <td>85.714286</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Multi-Label_KNN</th>\n",
        "      <td>36.226415</td>\n",
        "      <td>70.000000</td>\n",
        "      <td>46.666667</td>\n",
        "      <td>44.444444</td>\n",
        "      <td>24.000000</td>\n",
        "      <td>38.095238</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>37.500000</td>\n",
        "      <td>85.714286</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_MLP</th>\n",
        "      <td>34.951456</td>\n",
        "      <td>65.000000</td>\n",
        "      <td>17.391304</td>\n",
        "      <td>57.142857</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>27.272727</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Extra_Trees</th>\n",
        "      <td>34.594595</td>\n",
        "      <td>61.904762</td>\n",
        "      <td>30.000000</td>\n",
        "      <td>42.105263</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>35.294118</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>80.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Extra_Trees</th>\n",
        "      <td>33.846154</td>\n",
        "      <td>63.636364</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>42.105263</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>66.666667</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Random_Forest</th>\n",
        "      <td>31.284916</td>\n",
        "      <td>60.000000</td>\n",
        "      <td>10.526316</td>\n",
        "      <td>42.105263</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>26.666667</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>80.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Decision_Tree</th>\n",
        "      <td>30.985915</td>\n",
        "      <td>60.000000</td>\n",
        "      <td>21.428571</td>\n",
        "      <td>47.619048</td>\n",
        "      <td>34.782609</td>\n",
        "      <td>10.526316</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>22.222222</td>\n",
        "      <td>80.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Random_Forest</th>\n",
        "      <td>30.857143</td>\n",
        "      <td>68.181818</td>\n",
        "      <td>11.111111</td>\n",
        "      <td>12.500000</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>28.571429</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>80.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Ridge</th>\n",
        "      <td>29.050279</td>\n",
        "      <td>68.085106</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>33.333333</td>\n",
        "      <td>34.782609</td>\n",
        "      <td>26.666667</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_Decision_Tree</th>\n",
        "      <td>27.802691</td>\n",
        "      <td>61.111111</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>26.086957</td>\n",
        "      <td>34.782609</td>\n",
        "      <td>23.529412</td>\n",
        "      <td>15.384615</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>21.052632</td>\n",
        "      <td>36.363636</td>\n",
        "      <td>20.000000</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>80.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Classifier_Chain_Ridge</th>\n",
        "      <td>25.287356</td>\n",
        "      <td>63.636364</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>23.529412</td>\n",
        "      <td>34.782609</td>\n",
        "      <td>13.333333</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>50.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Binary_Relevance_kNN_B</th>\n",
        "      <td>2.264151</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>16.666667</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>18.181818</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.714286</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
      ]
    }
  ]
}